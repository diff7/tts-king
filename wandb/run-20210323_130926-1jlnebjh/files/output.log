Training:   0%|          | 0/900000 [00:00<?, ?it/s]
Epoch 1:   0%|          | 0/638 [00:00<?, ?it/s][ATraining:   0%|          | 2/900000 [00:02<297:10:37,  1.19s/it]Training:   0%|          | 3/900000 [00:03<277:08:07,  1.11s/it]Training:   0%|          | 4/900000 [00:04<234:52:08,  1.06it/s]Training:   0%|          | 5/900000 [00:04<206:08:25,  1.21it/s]
Epoch 1:   0%|          | 1/638 [00:04<49:14,  4.64s/it][ATraining:   0%|          | 6/900000 [00:06<293:48:59,  1.18s/it]Training:   0%|          | 7/900000 [00:07<279:29:52,  1.12s/it]Training:   0%|          | 8/900000 [00:08<258:56:36,  1.04s/it]Training:   0%|          | 9/900000 [00:08<219:56:47,  1.14it/s]
Epoch 1:   0%|          | 2/638 [00:08<46:51,  4.42s/it][ATraining:   0%|          | 10/900000 [00:10<281:40:53,  1.13s/it]Training:   0%|          | 11/900000 [00:11<267:48:27,  1.07s/it]Training:   0%|          | 12/900000 [00:12<242:47:55,  1.03it/s]Training:   0%|          | 13/900000 [00:12<207:10:11,  1.21it/s]
Epoch 1:   0%|          | 3/638 [00:12<44:07,  4.17s/it][ATraining:   0%|          | 14/900000 [00:14<275:48:14,  1.10s/it]Training:   0%|          | 15/900000 [00:15<273:32:54,  1.09s/it]Training:   0%|          | 16/900000 [00:16<264:11:58,  1.06s/it]Training:   0%|          | 17/900000 [00:17<227:23:18,  1.10it/s]
Epoch 1:   1%|          | 4/638 [00:17<44:48,  4.24s/it][ATraining:   0%|          | 18/900000 [00:18<282:54:05,  1.13s/it]Training:   0%|          | 19/900000 [00:19<274:49:21,  1.10s/it]Training:   0%|          | 20/900000 [00:20<247:20:33,  1.01it/s]Training:   0%|          | 21/900000 [00:21<213:15:33,  1.17it/s]
Epoch 1:   1%|          | 5/638 [00:21<43:35,  4.13s/it][ATraining:   0%|          | 22/900000 [00:22<265:35:15,  1.06s/it]Training:   0%|          | 23/900000 [00:23<243:09:12,  1.03it/s]Training:   0%|          | 24/900000 [00:23<216:35:18,  1.15it/s]Training:   0%|          | 25/900000 [00:24<195:27:51,  1.28it/s]
Epoch 1:   1%|          | 6/638 [00:24<41:19,  3.92s/it][ATraining:   0%|          | 26/900000 [00:26<267:27:56,  1.07s/it]Training:   0%|          | 27/900000 [00:27<260:27:30,  1.04s/it]Training:   0%|          | 28/900000 [00:27<229:33:02,  1.09it/s]Training:   0%|          | 29/900000 [00:28<201:11:14,  1.24it/s]
Epoch 1:   1%|          | 7/638 [00:28<41:08,  3.91s/it][ATraining:   0%|          | 30/900000 [00:30<268:42:22,  1.07s/it]Training:   0%|          | 31/900000 [00:31<265:15:48,  1.06s/it]Training:   0%|          | 32/900000 [00:32<257:34:31,  1.03s/it]Training:   0%|          | 33/900000 [00:32<218:32:32,  1.14it/s]
Epoch 1:   1%|â–         | 8/638 [00:32<42:02,  4.00s/it][ATraining:   0%|          | 34/900000 [00:34<295:08:19,  1.18s/it]Training:   0%|          | 35/900000 [00:35<273:17:21,  1.09s/it]Training:   0%|          | 36/900000 [00:36<240:22:44,  1.04it/s]Training:   0%|          | 37/900000 [00:36<210:32:38,  1.19it/s]
Epoch 1:   1%|â–         | 9/638 [00:36<41:58,  4.00s/it][ATraining:   0%|          | 38/900000 [00:38<278:17:31,  1.11s/it]Training:   0%|          | 39/900000 [00:39<271:39:10,  1.09s/it]Training:   0%|          | 40/900000 [00:40<250:29:38,  1.00s/it]Training:   0%|          | 41/900000 [00:40<221:07:06,  1.13it/s]
Epoch 1:   2%|â–         | 10/638 [00:40<42:29,  4.06s/it][ATraining:   0%|          | 42/900000 [00:42<295:18:11,  1.18s/it]Training:   0%|          | 43/900000 [00:43<283:34:47,  1.13s/it]Training:   0%|          | 44/900000 [00:44<252:54:12,  1.01s/it]Training:   0%|          | 45/900000 [00:45<216:26:57,  1.15it/s]
Epoch 1:   2%|â–         | 11/638 [00:45<42:42,  4.09s/it][ATraining:   0%|          | 46/900000 [00:46<262:06:03,  1.05s/it]Training:   0%|          | 47/900000 [00:47<257:39:50,  1.03s/it]Training:   0%|          | 48/900000 [00:48<236:20:56,  1.06it/s]Training:   0%|          | 49/900000 [00:48<205:11:47,  1.22it/s]
Epoch 1:   2%|â–         | 12/638 [00:48<41:32,  3.98s/it][ATraining:   0%|          | 50/900000 [00:50<289:57:39,  1.16s/it]Training:   0%|          | 51/900000 [00:51<277:01:15,  1.11s/it]Training:   0%|          | 52/900000 [00:52<242:50:50,  1.03it/s]Training:   0%|          | 53/900000 [00:52<209:55:05,  1.19it/s]
Epoch 1:   2%|â–         | 13/638 [00:52<41:55,  4.02s/it][ATraining:   0%|          | 54/900000 [00:54<271:13:06,  1.08s/it]Training:   0%|          | 55/900000 [00:55<265:43:04,  1.06s/it]Training:   0%|          | 56/900000 [00:56<235:17:32,  1.06it/s]Training:   0%|          | 57/900000 [00:56<208:42:44,  1.20it/s]
Epoch 1:   2%|â–         | 14/638 [00:56<41:30,  3.99s/it][ATraining:   0%|          | 58/900000 [00:58<278:51:11,  1.12s/it]Training:   0%|          | 59/900000 [00:59<267:31:22,  1.07s/it]Training:   0%|          | 60/900000 [01:00<229:09:43,  1.09it/s]Training:   0%|          | 61/900000 [01:00<198:52:40,  1.26it/s]
Epoch 1:   2%|â–         | 15/638 [01:00<40:51,  3.94s/it][ATraining:   0%|          | 62/900000 [01:02<265:19:20,  1.06s/it]Training:   0%|          | 63/900000 [01:03<257:56:47,  1.03s/it]Training:   0%|          | 64/900000 [01:04<253:00:06,  1.01s/it]Training:   0%|          | 65/900000 [01:04<225:16:34,  1.11it/s]
Epoch 1:   3%|â–Ž         | 16/638 [01:04<41:47,  4.03s/it][ATraining:   0%|          | 66/900000 [01:06<285:50:52,  1.14s/it]Training:   0%|          | 67/900000 [01:07<279:37:00,  1.12s/it]Training:   0%|          | 68/900000 [01:08<256:04:11,  1.02s/it]Training:   0%|          | 69/900000 [01:08<216:12:43,  1.16it/s]
Epoch 1:   3%|â–Ž         | 17/638 [01:08<41:49,  4.04s/it][ATraining:   0%|          | 70/900000 [01:10<287:27:24,  1.15s/it]Traceback (most recent call last):
  File "train.py", line 214, in <module>
    main(cfg, configs)
  File "train.py", line 107, in main
    optimizer.step_and_update_lr(losses)
  File "/home/dev/other/fsp/tts-king/fs_two/model/optimizer.py", line 336, in step_and_update_lr
    self._optimizer.pc_backward(losses)
  File "/home/dev/other/fsp/tts-king/fs_two/model/optimizer.py", line 41, in pc_backward
    pc_grad = self._project_conflicting(grads, has_grads)
  File "/home/dev/other/fsp/tts-king/fs_two/model/optimizer.py", line 59, in _project_conflicting
    for g in pc_grad]).sum(dim=0)
RuntimeError: CUDA out of memory. Tried to allocate 1.01 GiB (GPU 1; 23.65 GiB total capacity; 8.52 GiB already allocated; 882.06 MiB free; 12.35 GiB reserved in total by PyTorch)
